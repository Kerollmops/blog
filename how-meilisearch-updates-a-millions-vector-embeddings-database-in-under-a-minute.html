<!DOCTYPE html>
<html lang="en" data-bs-theme="auto">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script defer data-domain="blog.kerollmops.com" src="https://plausible.io/js/script.js"></script>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü¶Ä</text></svg>">
    <script type="application/javascript" src="/assets/script.js"></script>
    <script defer type="application/javascript" src="/assets/tiny-utterances.js"></script>
    <script type="application/javascript" src="/assets/matter.min.js"></script>
    <script type="application/javascript" src="/assets/balls.js"></script>
    <link href="assets/bootstrap.min.css" rel="stylesheet">
    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/tiny-utterances.css" rel="stylesheet">

    <!-- Primary Meta Tags -->
    <title>How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute</title>
    <meta name="title" content="How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute" />
    <meta name="description" content=" In this blog post, we'll explore how we implemented incremental indexing in Arroy, enabling efficient updates to our vector store without rebuilding the entire tree. This is crucial for Meilisearch, where content frequently changes. We discuss the theory, the challenges faced, and various approaches to optimize ID generation. Our method delivers a significant speedup, making our search system scalable and responsive, even for large datasets. We've achieved remarkable performance improvements, benefiting users with dynamic and extensive data. " />
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://blog.kerollmops.com/how-meilisearch-updates-a-millions-vector-embeddings-database-in-under-a-minute" />
    <meta property="og:title" content="How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute" />
    <meta property="og:description" content=" In this blog post, we'll explore how we implemented incremental indexing in Arroy, enabling efficient updates to our vector store without rebuilding the entire tree. This is crucial for Meilisearch, where content frequently changes. We discuss the theory, the challenges faced, and various approaches to optimize ID generation. Our method delivers a significant speedup, making our search system scalable and responsive, even for large datasets. We've achieved remarkable performance improvements, benefiting users with dynamic and extensive data. " />
    <meta property="og:image" content="https://blog.kerollmops.com/preview/how-meilisearch-updates-a-millions-vector-embeddings-database-in-under-a-minute.png" />
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta property="twitter:url" content="How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute" />
    <meta property="twitter:title" content="How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute" />
    <meta property="twitter:description" content=" In this blog post, we'll explore how we implemented incremental indexing in Arroy, enabling efficient updates to our vector store without rebuilding the entire tree. This is crucial for Meilisearch, where content frequently changes. We discuss the theory, the challenges faced, and various approaches to optimize ID generation. Our method delivers a significant speedup, making our search system scalable and responsive, even for large datasets. We've achieved remarkable performance improvements, benefiting users with dynamic and extensive data. " />
    <meta property="twitter:image" content="https://blog.kerollmops.com/preview/how-meilisearch-updates-a-millions-vector-embeddings-database-in-under-a-minute.png" />

    
  <meta name="description" content="Article by Tamo titled: How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute.">
  <link rel="stylesheet" href="/assets/starry-night.css">
  <style></style>

  </head>
  <body>
    <canvas id="ballsCanvas"></canvas>
    <div class="container">
      
<header class="profil">
  <a href="/">
      <div class="text-center">
          <img src="https://avatars.githubusercontent.com/u/7032172?v=4&s=100" class="profil-picture" alt="Profil picture of Tamo">
          <p class="long-text text-uppercase">Tamo</p>
      </div>
  </a>
</header>


      
    <p class="text-center">
        <small class="text-body-secondary"><i>March 25, 2024</i> ‚Äî <a href="https://github.com/Kerollmops/blog/issues/8#comment-composer-heading">0 comments</a></small>
    </p>
    <article>
        <h1 class="mb-4 text-center">How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute</h1>

        <html><head></head><body><div class="markdown-alert markdown-alert-note" dir="auto"><p class="markdown-alert-title" dir="auto"><svg aria-hidden="true" class="octicon octicon-info mr-2" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p><p dir="auto">This is one blog post in a series:</p>
<ul dir="auto">
<li><a href="https://blog.kerollmops.com/spotify-inspired-elevating-meilisearch-with-hybrid-search-and-rust" rel="nofollow">Spotify-Inspired: Elevating Meilisearch with Hybrid Search and Rust</a>,</li>
<li><a href="https://blog.kerollmops.com/multithreading-and-memory-mapping-refining-ann-performance-with-arroy-in-rust" rel="nofollow">Multithreading and Memory-Mapping: Refining ANN Performance with Arroy</a>,</li>
<li><a href="https://blog.kerollmops.com/meilisearch-expands-search-power-with-arroy-s-filtered-disk-ann" rel="nofollow">Meilisearch Expands Search Power with Arroy's Filtered Disk ANN</a>,</li>
<li>How Meilisearch Updates a Millions Vector Embeddings Database in Under a Minute,</li>
<li><a href="https://blog.kerollmops.com/meilisearch-indexes-embeddings-7x-faster-with-binary-quantization" rel="nofollow">Meilisearch Indexes Embeddings 7x Faster with Binary Quantization</a>.</li>
</ul>
</div>
<p dir="auto">In this blog post, we‚Äôll talk about how we implemented incremental indexing in Arroy.<br>
By incremental, we mean that when inserting or deleting items in a tree, we can update only the required parts instead of rebuilding everything.<br>
At Meilisearch, that‚Äôs essential because our users usually send updates regularly, and their content constantly changes.<br>
Rebuilding everything from scratch is very costly and won‚Äôt give a good experience; that‚Äôs why we already spent a lot of time on our latest release to make all the <a href="https://github.com/meilisearch/meiliSearch/releases/tag/v1.6.0">datastructures support incremental indexing</a> and arroy being one of them, we <em>HAD‚ÄØTO</em> implement it as well!</p>
<h3 id="the-theory" dir="auto"><a href="#the-theory">The Theory</a></h3>
<p dir="auto">The following schema shows a high-level view of what should happen when adding and deleting documents into an existing tree.<br>
As a reminder, arroy is a vector store based on LMDB, an embedded transactional memory-mapped key-value store. It stores your vectors in trees composed of three kinds of nodes:</p>
<ul dir="auto">
<li>The split nodes - Store information on which item IDs are spread out between its left and right.</li>
<li>The descendants' nodes - Store multiple item IDs.</li>
<li>The items - A‚ÄØsingle vector.</li>
</ul>
<p dir="auto">For the following examples, we‚Äôll consider the descendants node cannot contain <strong>more</strong> than two items and that the closer the IDs are, the closer the items are in space.<br>
For example, the item <code class="notranslate">1</code> is close to the item <code class="notranslate">2</code> but is farther from the item <code class="notranslate">10</code>.</p>
<p dir="auto"><a href="assets/images/d22eedd8c58253a6.png" rel="noopener noreferrer" target="_blank"><img alt="First step before inserting elements in the tree" src="assets/images/d22eedd8c58253a6.png" style="max-width: 100%;"></a></p>
<p dir="auto">Here, we‚Äôre trying to insert items <code class="notranslate">2</code> and <code class="notranslate">7</code> and delete items <code class="notranslate">3</code> and <code class="notranslate">11</code>.<br>
Following what we do on the search, we split the items to insert between the left and right split nodes.<br>
But the deleted items are no longer present in the database! We don't have their associated vector, and therefore we'll need to iterate over all the leaves to find and delete them.<br>
Fortunately, since we use roaring bitmaps, this list doesn't consume much memory, and since we never update it, we can share it with every thread without ever copying it üéâ</p>
<p dir="auto"><a href="assets/images/f8baf1b458e79ac4.png" rel="noopener noreferrer" target="_blank"><img alt="Second step inserting element in the tree" src="assets/images/f8baf1b458e79ac4.png" style="max-width: 100%;"></a></p>
<p dir="auto">Notice how the items to insert were balanced between the left and right split nodes.<br>
In the next step, we‚Äôll follow the same process and split both lists of items to insert on the split node.</p>
<p dir="auto"><a href="assets/images/f99e4dca7a067d99.png" rel="noopener noreferrer" target="_blank"><img alt="Third step inserting into elements in the tree" src="assets/images/f99e4dca7a067d99.png" style="max-width: 100%;"></a></p>
<p dir="auto">It‚Äôs on this step that all the good stuff happens. From the left to the right:</p>
<ul dir="auto">
<li>The first descendant node gets its item <code class="notranslate">3</code> removed, and item <code class="notranslate">2</code> added.</li>
<li>The second descendant node gets too big and must be replaced by a new split node.</li>
<li>The item <code class="notranslate">8</code> becomes a descendant containing both the items <code class="notranslate">7</code> and <code class="notranslate">8</code>.</li>
<li>After deleting item <code class="notranslate">10</code> in the last descendant node, we replace it with a direct link to an item to reduce the number of nodes in the tree (and improve search time by reducing the number of lookups).</li>
</ul>
<p dir="auto"><a href="assets/images/bbd9d8020d763208.png" rel="noopener noreferrer" target="_blank"><img alt="Last step inserting elements in the tree" src="assets/images/bbd9d8020d763208.png" style="max-width: 100%;"></a></p>
<p dir="auto">Now that you‚Äôve seen all the steps of our incremental indexing process, we‚Äôre still going to take a few notes on what happened:</p>
<ul dir="auto">
<li>In the first three steps, we had to read all of the tree nodes, which, by default, is equal to the total number of items in the database.</li>
<li>In the last step, we had to write four new tree nodes. Previously we would have rewritten the whole tree. The number of writes, which is the slowest operation in databases, is reduced to the bare minimum.</li>
<li>The process works on a single tree which means we can still multi-thread the computation of every tree.</li>
<li>The IDs aren‚Äôt sequential anymore, which doesn't play well with the ID generation strategy described in <a href="https://blog.kerollmops.com/multithreading-and-memory-mapping-refining-ann-performance-with-arroy" rel="nofollow">Writing the tree in parallel</a>.</li>
</ul>
<h3 id="how-did-we-fix-the-id-generation" dir="auto"><a href="#how-did-we-fix-the-id-generation">How Did We Fix the ID Generation?</a></h3>
<p dir="auto">At the start of the indexing process, we need to gather all the existing tree IDs.<br>
The information we need to generate new nodes are:</p>
<ul dir="auto">
<li>The total number of tree nodes used to know when to stop building trees.</li>
<li>The ¬´ holes ¬ª in the used IDs that we want to re-use. This fragmentation is produced when we edit the trees.</li>
<li>The highest ID existing in the trees to generate the next new IDs.</li>
</ul>
<p dir="auto"><a href="assets/images/be3c6cdc10063c4d.png" rel="noopener noreferrer" target="_blank"><img alt="Selecting the next ID in the Roaring Bitmap" src="assets/images/be3c6cdc10063c4d.png" style="max-width: 100%;"></a></p>
<p dir="auto">The ¬´ simple ¬ª idea is to have a counter for the total number of tree nodes. A counter that we can increment to generate new fresh IDs. The most challenging part is to pick an available ID shared between threads and without big mutexes. It took me quite some time to find a solution for this last point; I implemented a whole complex solution (150loc) that I‚ÄØended up <a href="https://github.com/meilisearch/arroy/pull/56/commits/0bf68e21cfd97ff00c7ef5a0ec116ba34c43c6a5">rewriting entirely from scratch</a> in one hour for an easy and more efficient solution. We're going to see all the ideas we went through before finding our final solution.</p>
<h4 id="sharing-an-iterator-over-the-available-ids" dir="auto"><a href="#sharing-an-iterator-over-the-available-ids">Sharing an Iterator Over the Available IDs</a></h4>
<p dir="auto">The first and most straightforward idea that comes to mind is to create and share an iterator over all the available IDs.</p>
<div class="highlight highlight-source-rust notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="let mut available_ids = available_ids.into_iter();

roots.into_par_iter().for_each(|root| {
    // stuff
    let next_id = available_ids.next();
    // stuff
});" dir="auto"><pre class="notranslate"><span class="pl-k">let</span> <span class="pl-k">mut</span> available_ids = available_ids<span class="pl-kos">.</span><span class="pl-en">into_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>

roots<span class="pl-kos">.</span><span class="pl-en">into_par_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">for_each</span><span class="pl-kos">(</span>|root| <span class="pl-kos">{</span>
    <span class="pl-c">// stuff</span>
    <span class="pl-k">let</span> next_id = available_ids<span class="pl-kos">.</span><span class="pl-en">next</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
    <span class="pl-c">// stuff</span>
<span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">;</span></pre></div>
<p dir="auto">If you‚Äôre familiar with Rust, you‚Äôll notice immediately that the <code class="notranslate">for_each</code> closure <em>cannot</em> capture a mutable reference over the <code class="notranslate">available_ids</code> because we use the <a href="https://docs.rs/rayon/latest/rayon/iter/trait.IntoParallelIterator.html#tymethod.into_par_iter" rel="nofollow"><code class="notranslate">into_par_iter</code></a> method from rayon that execute the next methods on the iterator in a multi-threaded way. Which means we can't call <code class="notranslate">.next()</code>.<br>
By using a mutex (short for <a href="https://en.wikipedia.org/wiki/Mutual_exclusion" rel="nofollow">mutual exclusion</a>), we can make it compile:</p>
<div class="highlight highlight-source-rust notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="let mut available_ids = Mutex::new(available_ids.into_iter());

roots.into_par_iter().for_each(|root| {
    // stuff
    let next_id = available_ids.lock().unwrap().next();
    // stuff
});" dir="auto"><pre class="notranslate"><span class="pl-k">let</span> <span class="pl-k">mut</span> available_ids = <span class="pl-smi">Mutex</span><span class="pl-kos">::</span><span class="pl-en">new</span><span class="pl-kos">(</span>available_ids<span class="pl-kos">.</span><span class="pl-en">into_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">)</span><span class="pl-kos">;</span>

roots<span class="pl-kos">.</span><span class="pl-en">into_par_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">for_each</span><span class="pl-kos">(</span>|root| <span class="pl-kos">{</span>
    <span class="pl-c">// stuff</span>
    <span class="pl-k">let</span> next_id = available_ids<span class="pl-kos">.</span><span class="pl-en">lock</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">unwrap</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">next</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
    <span class="pl-c">// stuff</span>
<span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">;</span></pre></div>
<p dir="auto">That is safe and will yield the right results, but won‚Äôt scale well as all the threads have to wait for each other on the lock.</p>
<h4 id="let-each-thread-own-its-list-of-ids" dir="auto"><a href="#let-each-thread-own-its-list-of-ids">Let Each Thread Own Its List of IDs</a></h4>
<p dir="auto">When you need to remove a lock, a common solution is to split the work beforehand so each thread can work to its full capacity without ever having to know what‚Äôs happening on the other threads. That‚Äôs the solution <a href="https://github.com/meilisearch/arroy/pull/56/files/dc782ea61ef84f0ad8ad20e092476494d6eacc0c">I implemented initially</a>. The idea is to explode the roaring bitmap into as many smaller roaring bitmaps as there are trees to update.</p>
<p dir="auto">The following function can split a roaring bitmap into <code class="notranslate">n</code> sub-bitmaps of equal size:</p>
<div class="highlight highlight-source-rust notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pub fn split_ids_in(available: RoaringBitmap, n: usize) -> Vec<RoaringBitmap> {
    // Define the number of elements per sub-bitmap
    let chunk_size = available.len() / n as u64;
    let mut ret = Vec::new();

    let mut iter = available.into_iter();
    for _ in 0..(n - 1) {
        // Create a roaring bitmap of `chunk_size` elements from the iterator without consuming it
        let available: RoaringBitmap = iter.by_ref().take(chunk_size as usize).collect();
        ret.push(available);
    }
    // the last element is going to contain everything remaining
    ret.extend(iter);

    ret
}" dir="auto"><pre class="notranslate"><span class="pl-k">pub</span> <span class="pl-k">fn</span> <span class="pl-en">split_ids_in</span><span class="pl-kos">(</span><span class="pl-s1">available</span><span class="pl-kos">:</span> <span class="pl-smi">RoaringBitmap</span><span class="pl-kos">,</span> <span class="pl-s1">n</span><span class="pl-kos">:</span> <span class="pl-smi">usize</span><span class="pl-kos">)</span> -&gt; <span class="pl-smi">Vec</span><span class="pl-kos">&lt;</span><span class="pl-smi">RoaringBitmap</span><span class="pl-kos">&gt;</span> <span class="pl-kos">{</span>
    <span class="pl-c">// Define the number of elements per sub-bitmap</span>
    <span class="pl-k">let</span> chunk_size = available<span class="pl-kos">.</span><span class="pl-en">len</span><span class="pl-kos">(</span><span class="pl-kos">)</span> / n <span class="pl-k">as</span> <span class="pl-smi">u64</span><span class="pl-kos">;</span>
    <span class="pl-k">let</span> <span class="pl-k">mut</span> ret = <span class="pl-smi">Vec</span><span class="pl-kos">::</span><span class="pl-en">new</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>

    <span class="pl-k">let</span> <span class="pl-k">mut</span> iter = available<span class="pl-kos">.</span><span class="pl-en">into_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
    <span class="pl-k">for</span> _ <span class="pl-k">in</span> <span class="pl-c1">0</span>..<span class="pl-kos">(</span>n - <span class="pl-c1">1</span><span class="pl-kos">)</span> <span class="pl-kos">{</span>
        <span class="pl-c">// Create a roaring bitmap of `chunk_size` elements from the iterator without consuming it</span>
        <span class="pl-k">let</span> available<span class="pl-kos">:</span> <span class="pl-smi">RoaringBitmap</span> = iter<span class="pl-kos">.</span><span class="pl-en">by_ref</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">take</span><span class="pl-kos">(</span>chunk_size <span class="pl-k">as</span> <span class="pl-smi">usize</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">collect</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
        ret<span class="pl-kos">.</span><span class="pl-en">push</span><span class="pl-kos">(</span>available<span class="pl-kos">)</span><span class="pl-kos">;</span>
    <span class="pl-kos">}</span>
    <span class="pl-c">// the last element is going to contain everything remaining</span>
    ret<span class="pl-kos">.</span><span class="pl-en">extend</span><span class="pl-kos">(</span>iter<span class="pl-kos">)</span><span class="pl-kos">;</span>

    ret
<span class="pl-kos">}</span></pre></div>
<p dir="auto">With this function available, it's then trivial to use one bitmap per tree to update with the <a href="https://docs.rs/rayon/latest/rayon/iter/trait.IndexedParallelIterator.html#method.zip" rel="nofollow"><code class="notranslate">zip</code></a> method on the parallel iterators of Rayon:</p>
<div class="highlight highlight-source-rust notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="let available_ids = split_ids_in(available_ids, roots.len());

roots.into_par_iter().zip(available_ids).for_each(|(root, available_ids)| {
    let mut available_ids = available_ids.into_iter();
    // stuff
    let next_id = available_ids.next();
    // Here, we can use the available_ids without any locks or inter-thread synchronization
    // stuff
});" dir="auto"><pre class="notranslate"><span class="pl-k">let</span> available_ids = <span class="pl-en">split_ids_in</span><span class="pl-kos">(</span>available_ids<span class="pl-kos">,</span> roots<span class="pl-kos">.</span><span class="pl-en">len</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">)</span><span class="pl-kos">;</span>

roots<span class="pl-kos">.</span><span class="pl-en">into_par_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">zip</span><span class="pl-kos">(</span>available_ids<span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">for_each</span><span class="pl-kos">(</span>|<span class="pl-kos">(</span>root<span class="pl-kos">,</span> available_ids<span class="pl-kos">)</span>| <span class="pl-kos">{</span>
    <span class="pl-k">let</span> <span class="pl-k">mut</span> available_ids = available_ids<span class="pl-kos">.</span><span class="pl-en">into_iter</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
    <span class="pl-c">// stuff</span>
    <span class="pl-k">let</span> next_id = available_ids<span class="pl-kos">.</span><span class="pl-en">next</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
    <span class="pl-c">// Here, we can use the available_ids without any locks or inter-thread synchronization</span>
    <span class="pl-c">// stuff</span>
<span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">;</span></pre></div>
<p dir="auto">This works well while we're updating the already existing root trees.</p>
<p dir="auto">But later on, we may want to create new trees from scratch, and we can't know in advance how many new trees we‚Äôll need to create. That's an issue because, without this information, we don't know how many sub-bitmaps we need to create. At this point, I couldn‚Äôt see an easy fix to this problem, but I made the assumption that we rarely create a lot of new trees and that all new trees would use a lot of IDs. This means, giving all the IDs to the <strong>first</strong> new tree would <em>probably work out</em>. (it‚Äôs hard to be 100% sure without monitoring it in prod)</p>
<h4 id="the-final-solution" dir="auto"><a href="#the-final-solution">The Final Solution</a></h4>
<p dir="auto">The previous solution was complex and did not even work perfectly.<br>
While I was scrolling through the documentation of the Roaring Bitmap, I saw <a href="https://docs.rs/roaring/latest/roaring/bitmap/struct.RoaringBitmap.html#method.select" rel="nofollow">the <code class="notranslate">select</code> method</a> and immediately understood how I could make the initial approach works.<br>
This method lets you get the values in your bitmap by index in an efficient way.<br>
For example, with the following values in a bitmap: <code class="notranslate">13, 14, 15, 98, 99, 100</code>:</p>
<ul dir="auto">
<li><code class="notranslate">select(0)</code> returns <code class="notranslate">13</code>.</li>
<li><code class="notranslate">select(3)</code> returns <code class="notranslate">98</code>.</li>
<li><code class="notranslate">select(5)</code> returns <code class="notranslate">100</code>.</li>
<li><code class="notranslate">select(6)</code> returns <code class="notranslate">None</code>.</li>
</ul>
<p dir="auto">With that in mind, if we share the bitmap with all threads in <strong>read-only</strong> and share the index in the bitmap as an atomic number, we can have multiple threads get available IDs at the same time with lock-free synchronization. Once the <code class="notranslate">select</code> method returns <code class="notranslate">None</code>, it means we can stop picking IDs from the bitmap and instead simply generate new IDs from scratch with the old method.<br>
Even if it's super fast, calling the <code class="notranslate">select</code> method still takes some time, so once a thread gets a <code class="notranslate">None</code> returned from the method, we're going to update an atomic boolean telling us if there are still values to look at in the bitmap. If not, we can skip calling <code class="notranslate">select</code> and directly generate a new ID.</p>
<p dir="auto">With that in mind, the cool <code class="notranslate">ConcurrentNodeIds</code> structure we showed you before in part 2 got a little bit more complex but it still let us generate IDs fairly without any locks!</p>
<div class="highlight highlight-source-rust notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="/// A concurrent ID generator that will never return the same ID twice.
pub struct ConcurrentNodeIds {
    /// The current tree node ID we should use if no other IDs are available.
    current: AtomicU32,
    /// The total number of tree node IDs used.
    used: AtomicU64,

    /// A list of IDs to exhaust before picking IDs from `current`.
    available: RoaringBitmap,
    /// The current Nth ID to select in the bitmap.
    select_in_bitmap: AtomicU32,
    /// Tells if you should look in the roaring bitmap or if all the IDs are already exhausted.
    look_into_bitmap: AtomicBool,
}

impl ConcurrentNodeIds {
    /// Creates an ID generator returning unique IDs, avoiding the specified used IDs.
    pub fn new(used: RoaringBitmap) -> ConcurrentNodeIds {
        let last_id = used.max().map_or(0, |id| id + 1);
        let used_ids = used.len();
        let available = RoaringBitmap::from_sorted_iter(0..last_id).unwrap() - used;

        ConcurrentNodeIds {
            current: AtomicU32::new(last_id),
            used: AtomicU64::new(used_ids),
            select_in_bitmap: AtomicU32::new(0),
            look_into_bitmap: AtomicBool::new(!available.is_empty()),
            available,
        }
    }

    /// Returns a new unique ID and increases the count of IDs used.
    pub fn next(&amp;self) -> Result<u32> {
        if self.look_into_bitmap.load(Ordering::Relaxed) {
            let current = self.select_in_bitmap.fetch_add(1, Ordering::Relaxed);
            match self.available.select(current) {
                Some(id) => Ok(id),
                None => {
                    self.look_into_bitmap.store(false, Ordering::Relaxed);
                    Ok(self.current.fetch_add(1, Ordering::Relaxed))
                }
            }
        } else {
            Ok(self.current.fetch_add(1, Ordering::Relaxed))
        }
    }
}" dir="auto"><pre class="notranslate"><span class="pl-c">/// A concurrent ID generator that will never return the same ID twice.</span>
<span class="pl-c"></span><span class="pl-k">pub</span> <span class="pl-k">struct</span> <span class="pl-smi">ConcurrentNodeIds</span> <span class="pl-kos">{</span>
    <span class="pl-c">/// The current tree node ID we should use if no other IDs are available.</span>
<span class="pl-c"></span>    <span class="pl-c1">current</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicU32</span><span class="pl-kos">,</span>
    <span class="pl-c">/// The total number of tree node IDs used.</span>
<span class="pl-c"></span>    <span class="pl-c1">used</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicU64</span><span class="pl-kos">,</span>

    <span class="pl-c">/// A list of IDs to exhaust before picking IDs from `current`.</span>
<span class="pl-c"></span>    <span class="pl-c1">available</span><span class="pl-kos">:</span> <span class="pl-smi">RoaringBitmap</span><span class="pl-kos">,</span>
    <span class="pl-c">/// The current Nth ID to select in the bitmap.</span>
<span class="pl-c"></span>    <span class="pl-c1">select_in_bitmap</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicU32</span><span class="pl-kos">,</span>
    <span class="pl-c">/// Tells if you should look in the roaring bitmap or if all the IDs are already exhausted.</span>
<span class="pl-c"></span>    <span class="pl-c1">look_into_bitmap</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicBool</span><span class="pl-kos">,</span>
<span class="pl-kos">}</span>

<span class="pl-k">impl</span> <span class="pl-smi">ConcurrentNodeIds</span> <span class="pl-kos">{</span>
    <span class="pl-c">/// Creates an ID generator returning unique IDs, avoiding the specified used IDs.</span>
<span class="pl-c"></span>    <span class="pl-k">pub</span> <span class="pl-k">fn</span> <span class="pl-en">new</span><span class="pl-kos">(</span><span class="pl-s1">used</span><span class="pl-kos">:</span> <span class="pl-smi">RoaringBitmap</span><span class="pl-kos">)</span> -&gt; <span class="pl-smi">ConcurrentNodeIds</span> <span class="pl-kos">{</span>
        <span class="pl-k">let</span> last_id = used<span class="pl-kos">.</span><span class="pl-en">max</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">map_or</span><span class="pl-kos">(</span><span class="pl-c1">0</span><span class="pl-kos">,</span> |id| id + <span class="pl-c1">1</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
        <span class="pl-k">let</span> used_ids = used<span class="pl-kos">.</span><span class="pl-en">len</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
        <span class="pl-k">let</span> available = <span class="pl-smi">RoaringBitmap</span><span class="pl-kos">::</span><span class="pl-en">from_sorted_iter</span><span class="pl-kos">(</span><span class="pl-c1">0</span>..last_id<span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-en">unwrap</span><span class="pl-kos">(</span><span class="pl-kos">)</span> - used<span class="pl-kos">;</span>

        <span class="pl-smi">ConcurrentNodeIds</span> <span class="pl-kos">{</span>
            <span class="pl-c1">current</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicU32</span><span class="pl-kos">::</span><span class="pl-en">new</span><span class="pl-kos">(</span>last_id<span class="pl-kos">)</span><span class="pl-kos">,</span>
            <span class="pl-c1">used</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicU64</span><span class="pl-kos">::</span><span class="pl-en">new</span><span class="pl-kos">(</span>used_ids<span class="pl-kos">)</span><span class="pl-kos">,</span>
            <span class="pl-c1">select_in_bitmap</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicU32</span><span class="pl-kos">::</span><span class="pl-en">new</span><span class="pl-kos">(</span><span class="pl-c1">0</span><span class="pl-kos">)</span><span class="pl-kos">,</span>
            <span class="pl-c1">look_into_bitmap</span><span class="pl-kos">:</span> <span class="pl-smi">AtomicBool</span><span class="pl-kos">::</span><span class="pl-en">new</span><span class="pl-kos">(</span>!available<span class="pl-kos">.</span><span class="pl-en">is_empty</span><span class="pl-kos">(</span><span class="pl-kos">)</span><span class="pl-kos">)</span><span class="pl-kos">,</span>
            available<span class="pl-kos">,</span>
        <span class="pl-kos">}</span>
    <span class="pl-kos">}</span>

    <span class="pl-c">/// Returns a new unique ID and increases the count of IDs used.</span>
<span class="pl-c"></span>    <span class="pl-k">pub</span> <span class="pl-k">fn</span> <span class="pl-en">next</span><span class="pl-kos">(</span><span class="pl-c1">&amp;</span><span class="pl-smi">self</span><span class="pl-kos">)</span> -&gt; <span class="pl-smi">Result</span><span class="pl-kos">&lt;</span><span class="pl-smi">u32</span><span class="pl-kos">&gt;</span> <span class="pl-kos">{</span>
        <span class="pl-k">if</span> <span class="pl-smi">self</span><span class="pl-kos">.</span><span class="pl-c1">look_into_bitmap</span><span class="pl-kos">.</span><span class="pl-en">load</span><span class="pl-kos">(</span><span class="pl-smi">Ordering</span><span class="pl-kos">::</span><span class="pl-v">Relaxed</span><span class="pl-kos">)</span> <span class="pl-kos">{</span>
            <span class="pl-k">let</span> current = <span class="pl-smi">self</span><span class="pl-kos">.</span><span class="pl-c1">select_in_bitmap</span><span class="pl-kos">.</span><span class="pl-en">fetch_add</span><span class="pl-kos">(</span><span class="pl-c1">1</span><span class="pl-kos">,</span> <span class="pl-smi">Ordering</span><span class="pl-kos">::</span><span class="pl-v">Relaxed</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
            <span class="pl-k">match</span> <span class="pl-smi">self</span><span class="pl-kos">.</span><span class="pl-c1">available</span><span class="pl-kos">.</span><span class="pl-en">select</span><span class="pl-kos">(</span>current<span class="pl-kos">)</span> <span class="pl-kos">{</span>
                <span class="pl-v">Some</span><span class="pl-kos">(</span>id<span class="pl-kos">)</span> =&gt; <span class="pl-en">Ok</span><span class="pl-kos">(</span>id<span class="pl-kos">)</span><span class="pl-kos">,</span>
                <span class="pl-v">None</span> =&gt; <span class="pl-kos">{</span>
                    <span class="pl-smi">self</span><span class="pl-kos">.</span><span class="pl-c1">look_into_bitmap</span><span class="pl-kos">.</span><span class="pl-en">store</span><span class="pl-kos">(</span><span class="pl-c1">false</span><span class="pl-kos">,</span> <span class="pl-smi">Ordering</span><span class="pl-kos">::</span><span class="pl-v">Relaxed</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
                    <span class="pl-en">Ok</span><span class="pl-kos">(</span><span class="pl-smi">self</span><span class="pl-kos">.</span><span class="pl-c1">current</span><span class="pl-kos">.</span><span class="pl-en">fetch_add</span><span class="pl-kos">(</span><span class="pl-c1">1</span><span class="pl-kos">,</span> <span class="pl-smi">Ordering</span><span class="pl-kos">::</span><span class="pl-v">Relaxed</span><span class="pl-kos">)</span><span class="pl-kos">)</span>
                <span class="pl-kos">}</span>
            <span class="pl-kos">}</span>
        <span class="pl-kos">}</span> <span class="pl-k">else</span> <span class="pl-kos">{</span>
            <span class="pl-en">Ok</span><span class="pl-kos">(</span><span class="pl-smi">self</span><span class="pl-kos">.</span><span class="pl-c1">current</span><span class="pl-kos">.</span><span class="pl-en">fetch_add</span><span class="pl-kos">(</span><span class="pl-c1">1</span><span class="pl-kos">,</span> <span class="pl-smi">Ordering</span><span class="pl-kos">::</span><span class="pl-v">Relaxed</span><span class="pl-kos">)</span><span class="pl-kos">)</span>
        <span class="pl-kos">}</span>
    <span class="pl-kos">}</span>
<span class="pl-kos">}</span></pre></div>
<h3 id="performances-in-practice" dir="auto"><a href="#performances-in-practice">Performances in Practice</a></h3>
<p dir="auto">I haven‚Äôt run a lot of benchmarks yet (I would like to, though, and may update this post later), but on my benchmarks with a few hundred thousand items, here are the results I get:</p>
<p dir="auto"><a href="assets/images/411c58c8cd2c36e0.png" rel="noopener noreferrer" target="_blank"><img alt="Performance improvement showed on a graph" src="assets/images/411c58c8cd2c36e0.png" style="max-width: 100%;"></a></p>
<ul dir="auto">
<li>On average, we get more than a 10x speedup after three batches of items indexed.</li>
<li>The little bumps we observe afterward that make us go from ~700ms to ~3s are due to the creation of new trees as the number of items increases.</li>
<li>I expect this benchmark to represent a worst-case scenario:
<ul dir="auto">
<li>All my item IDs are randomly generated, which means there are very few duplicates/updates but always new insertions and more writing.</li>
<li>My vectors are also randomly generated with a uniform distribution, which means there shouldn‚Äôt be clusters as we observe in a real-life dataset.</li>
</ul>
</li>
</ul>
<p dir="auto">This feature is now being used on production data with millions of documents, and we've seen numbers in the range of 9000 items added on a 2M items database in under a minute.</p></body></html>
    </article>

    <div class="vote-emojis">
    <a class="btn btn-outline-secondary vote-emoji" href="https://github.com/Kerollmops/blog/issues/8#comment-composer-heading" role="button">üôÇ ‚úö</a>

    

    

    

    
        <a class="btn btn-outline-secondary vote-emoji" href="https://github.com/Kerollmops/blog/issues/8#comment-composer-heading" role="button">‚ù§Ô∏è 2</a>
    

    

    

    
        <a class="btn btn-outline-secondary vote-emoji" href="https://github.com/Kerollmops/blog/issues/8#comment-composer-heading" role="button">üöÄ 5</a>
    

    
    </div>

    <div class="tiny-utterances"
        data-repo-owner="Kerollmops"
        data-repo-name="blog"
        data-issue-number="8"
        data-max-comments="10">
        <a class="tu-button"
            href="https://github.com/Kerollmops/blog/issues/8#comment-composer-heading">
            0 comments, join the discussion
        </a>
    </div>


      
  <footer class="profil text-center">
    <p class="long-text text-uppercase">About Tamo</p>
    <p class="text-center">I like rust</p>
    <hr class="mb-3"/>
    <p class="text-center">Subscribe to <a href="/atom.xml">my RSS/Atom feed</a> for the latest updates and articles.</p>
  </footer>

    </div>
  </body>
</html>